{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 10:18:28.074553: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-06 10:18:28.685023: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "from functools import partial\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.utils import _term_move_up\n",
    "\n",
    "prefix = _term_move_up() + '\\r'\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# from mamba import Mamba, MambaConfig\n",
    "from mamba_ssm import Mamba\n",
    "# from mamba_ssm.modules.mamba_simple import Block\n",
    "from mamba_ssm.models.mixer_seq_simple import create_block, _init_weights\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "from data import DrawingDataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce GTX 1080\n",
      "_CudaDeviceProperties(name='NVIDIA GeForce GTX 1080', major=6, minor=1, total_memory=8110MB, multi_processor_count=20)\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name())\n",
    "print(torch.cuda.get_device_properties(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 25/345 [00:10<02:10,  2.45it/s]\n",
      "  7%|▋         | 25/345 [00:00<00:04, 67.62it/s]\n",
      "  7%|▋         | 25/345 [00:00<00:05, 63.92it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "max_length = 100\n",
    "\n",
    "train_dataset = DrawingDataset(data_path=\"./data\", split=\"train\", max_length=max_length)\n",
    "val_dataset = DrawingDataset(data_path=\"./data\", split=\"valid\", max_length=max_length)\n",
    "test_dataset = DrawingDataset(data_path=\"./data\", split=\"test\", max_length=max_length)\n",
    "\n",
    "train = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class mambaBlock(nn.Module):\n",
    "#     def __init__(self, d_model, d_state, d_conv, expand, n_layers):\n",
    "#         super(mambaBlock, self).__init__()\n",
    "#         self.d_model = d_model\n",
    "#         self.d_state = d_state\n",
    "#         self.d_conv = d_conv\n",
    "#         self.expand = expand\n",
    "#         self.n_layers = n_layers\n",
    "#         self.layers = []\n",
    "\n",
    "#         self.layers = nn.ModuleList([Mamba(d_model, d_state, d_conv, expand) for _ in range(n_layers)])\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         for layer in self.layers:\n",
    "#             x = layer(x)\n",
    "#         return x\n",
    "\n",
    "class customModel(nn.Module):\n",
    "    def __init__(self, nb, no, ns, embed_dim, state_hidden):\n",
    "        super(customModel, self).__init__()\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.state_hidden = state_hidden\n",
    "        self.proj = nn.Linear(in_features=5, out_features=self.embed_dim, bias=False)\n",
    "        \n",
    "        self.m1 = nn.ModuleList([create_block(self.embed_dim , device='cuda', layer_idx=f'm{i}') for i in range(nb)])\n",
    "        self.leftm = nn.ModuleList([create_block(self.embed_dim , device='cuda', layer_idx=f'l{i}') for i in range(no)])\n",
    "        self.rightm = nn.ModuleList([create_block(self.embed_dim , device='cuda', layer_idx=f'r{i}') for i in range(ns)])\n",
    "        \n",
    "        self.offset_out = nn.Linear(in_features=self.embed_dim, out_features=2, bias=False)\n",
    "        self.state_out = nn.Linear(in_features=self.embed_dim, out_features=3, bias=False)\n",
    "        \n",
    "        initializer_cfg = None\n",
    "        for layer in self.m1:\n",
    "            layer.apply(partial(_init_weights, n_layer=nb, **(initializer_cfg if initializer_cfg is not None else {})))\n",
    "        for layer in self.leftm:\n",
    "            layer.apply(partial(_init_weights, n_layer=no, **(initializer_cfg if initializer_cfg is not None else {})))\n",
    "        for layer in self.rightm:\n",
    "            layer.apply(partial(_init_weights, n_layer=ns, **(initializer_cfg if initializer_cfg is not None else {})))\n",
    "        \n",
    "            \n",
    "\n",
    "    def forward(self, x): # x is of shape (B, L, 5) (Batchsize, sequence length, dimension)\n",
    "        x = self.proj(x)\n",
    "        hidden_states, residuals = x, None\n",
    "        for layer in self.m1:\n",
    "            hidden_states, residuals = layer(hidden_states, residuals)\n",
    "        \n",
    "        left_hidden_states, left_residuals = hidden_states, residuals\n",
    "        right_hidden_states, right_residuals = hidden_states, residuals\n",
    "\n",
    "        for layer in self.leftm:\n",
    "            left_hidden_states, left_residuals = layer(left_hidden_states, left_residuals)\n",
    "        for layer in self.rightm:\n",
    "            right_hidden_states, right_residuals = layer(right_hidden_states, right_residuals)\n",
    "        \n",
    "        offset_out = self.offset_out(left_hidden_states)\n",
    "        state_out = self.state_out(right_hidden_states)\n",
    "        return offset_out, state_out\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def generate(self, input_seq):\n",
    "        prev = input_seq\n",
    "        \n",
    "        i = 0\n",
    "        while i < 10:\n",
    "            offset, state = self.forward(prev)\n",
    "            pred = torch.cat((offset, state), dim=-1)\n",
    "            next_seg = pred[:, -1:, :]\n",
    "            prev = torch.cat((prev, next_seg), dim=1)\n",
    "            i += 1\n",
    "        \n",
    "        return prev\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "    \n",
    "    def load(self, path):\n",
    "        self.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004450630173874167\n"
     ]
    }
   ],
   "source": [
    "log_interval = 10\n",
    "epochs = 5\n",
    "\n",
    "batches = len(train)\n",
    "\n",
    "model = customModel(nb=4, no=2, ns=2, embed_dim=32, state_hidden=128).to(\"cuda\")\n",
    "\n",
    "offset_crit = nn.MSELoss(reduction='none')\n",
    "state_crit = nn.CrossEntropyLoss(ignore_index=2)\n",
    "\n",
    "#optimizer = torch.optim.RAdam(model.parameters(), lr=5e-4)\n",
    "warmup_ratio = 0.03\n",
    "\n",
    "print(0.05 * math.sqrt(batch_size / (batches * epochs)))\n",
    "optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                              lr=1e-4, betas=(0.99, 0.95), eps=1e-4,\n",
    "                              weight_decay=0.05 * math.sqrt(batch_size / (batches * epochs)))   \n",
    "# scheduler = get_cosine_schedule_with_warmup(optimizer, \n",
    "#                                             num_warmup_steps=batches * warmup_ratio,\n",
    "#                                             num_training_steps=batches)\n",
    "\n",
    "writer = SummaryWriter('./logs')\n",
    "\n",
    "def train_model(model, data_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    size = len(data_loader)\n",
    "    \n",
    "    # Total Losses\n",
    "    total_loss = 0\n",
    "    total_offset_loss = 0\n",
    "    total_state_loss = 0\n",
    "    \n",
    "    # Running Losses\n",
    "    running_loss = 0\n",
    "    running_offset_loss = 0\n",
    "    running_state_loss = 0\n",
    "    \n",
    "    running_correct = 0\n",
    "    running_total = 0\n",
    "    \n",
    "    running_mse = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i, data in enumerate(tqdm(data_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inputs, targets = data\n",
    "        inputs = inputs.to(\"cuda\")\n",
    "        targets = targets.to(\"cuda\")\n",
    "        \n",
    "        offsets, states = model(inputs)\n",
    "        \n",
    "        # Split Target\n",
    "        offset_target = targets[:, :, :2]\n",
    "        state_target = targets[:, :, 2:].argmax(dim=-1)\n",
    "        no_pad_mask = state_target != 2\n",
    "        \n",
    "        # Masked MSE Loss for offset\n",
    "        offset_loss = offset_crit(offsets, offset_target)\n",
    "        offset_loss_mask = offset_loss * no_pad_mask.unsqueeze(-1).float()\n",
    "        \n",
    "        offset_loss = offset_loss_mask.sum() / no_pad_mask.sum()\n",
    "        \n",
    "        # Cross Entropy Loss for State\n",
    "        state_loss = state_crit(states.transpose(1, 2), state_target)\n",
    "        loss = offset_loss + state_loss\n",
    "        \n",
    "        # Calculate other metrics (accuracy)\n",
    "        with torch.no_grad():\n",
    "            states_softmax = torch.nn.functional.softmax(states, dim=-1)\n",
    "            states_pred = states_softmax.argmax(dim=-1)\n",
    "            \n",
    "            no_pad_mask = state_target.flatten() != 2\n",
    "\n",
    "            running_correct += (states_pred.flatten()[no_pad_mask] == state_target.flatten()[no_pad_mask]).sum().item()\n",
    "            running_total += states_pred.flatten()[no_pad_mask].size().numel()\n",
    "            \n",
    "            flat_offsets_pred = offsets.reshape(-1, 2)[no_pad_mask, :]\n",
    "            flat_offset_target = targets[:, :, :2].reshape(-1, 2)[no_pad_mask, :]\n",
    "            running_mse += nn.functional.mse_loss(flat_offsets_pred, flat_offset_target)\n",
    "        \n",
    "        # Backprop\n",
    "        loss.backward(retain_graph=True)\n",
    "        \n",
    "        # Gradient Clipping\n",
    "        for name, param in model.named_parameters():\n",
    "            torch.nn.utils.clip_grad_norm_(param, max_norm=1.0)\n",
    "        \n",
    "        # Optimizer Steps\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        running_offset_loss += offset_loss.item()\n",
    "        running_state_loss += state_loss.item()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_offset_loss += offset_loss.item()\n",
    "        total_state_loss += state_loss.item()\n",
    "        \n",
    "        # Print speed, losses, and accuracy every 25 batchs\n",
    "        if i % log_interval == 0 and i > 0:\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = running_loss / log_interval\n",
    "            cur_offset_loss = running_offset_loss / log_interval\n",
    "            cur_state_loss = running_state_loss / log_interval\n",
    "            cur_accuracy = running_correct / running_total\n",
    "            cur_mse = running_mse / log_interval\n",
    "            tqdm.write(f'{prefix}| epoch {(epoch+1):3d} | {i:5d}/{size:5d} batches '\n",
    "                  f'| ms/batch {ms_per_batch:5.2f} | '\n",
    "                  f'offset_loss {cur_offset_loss:5.2f} | state_loss {cur_state_loss:5.4f} | '\n",
    "                  f'accuracy {cur_accuracy:5.4f} | mse {cur_mse:5.2f}')\n",
    "            time.sleep(0)\n",
    "            running_loss = 0\n",
    "            running_offset_loss = 0\n",
    "            running_state_loss = 0\n",
    "            running_correct = 0\n",
    "            running_total = 0\n",
    "            running_mse = 0\n",
    "            start_time = time.time()\n",
    "    \n",
    "    return total_loss / size, total_offset_loss / size, total_state_loss / size\n",
    "        \n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    size = len(data_loader)\n",
    "    \n",
    "    # Running Losses\n",
    "    running_loss = 0\n",
    "    running_offset_loss = 0\n",
    "    running_state_loss = 0\n",
    "    \n",
    "    # Correct\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(data_loader):\n",
    "            inputs, targets = data\n",
    "            inputs = inputs.to(\"cuda\")\n",
    "            targets = targets.to(\"cuda\")\n",
    "            \n",
    "            offsets, states = model(inputs)\n",
    "            \n",
    "            # Masked MSE Loss\n",
    "            offset_target = targets[:, :, :2]\n",
    "            state_target = targets[:, :, 2:].argmax(dim=-1)\n",
    "            no_pad_mask = state_target != 2\n",
    "            \n",
    "            offset_loss = offset_crit(offsets, offset_target)\n",
    "            offset_loss_mask = offset_loss * no_pad_mask.unsqueeze(-1).float()\n",
    "            offset_loss = offset_loss_mask.sum() / no_pad_mask.sum()\n",
    "            \n",
    "            state_loss = state_crit(states.transpose(1, 2), state_target)\n",
    "            loss = offset_loss + state_loss\n",
    "            \n",
    "            # Accuracy Calculation\n",
    "            states_softmax = torch.nn.functional.softmax(states, dim=-1)\n",
    "            states_pred = states_softmax.argmax(dim=-1)\n",
    "            \n",
    "            no_pad_mask = no_pad_mask.flatten()\n",
    "            \n",
    "            correct += (states_pred.flatten()[no_pad_mask] == state_target.flatten()[no_pad_mask]).sum().item()\n",
    "            total_samples += states_pred.flatten()[no_pad_mask].size().numel()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_offset_loss += offset_loss.item()\n",
    "            running_state_loss += state_loss.item()\n",
    "    \n",
    "    return running_loss / size, running_offset_loss / size, running_state_loss / size, correct / total_samples\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348500859b594ba88c1be773c89376a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |  6460/ 6462 batches | ms/batch 97.25 | offset_loss 3701.53 | state_loss 0.2895 | accuracy 0.8976 | mse 1850.775\n",
      "Training: Epoch: 1, offset_loss: 4929.4532, state_loss: 0.3609\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "051b5fcd37ed45c7be4c38c376fa9a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Epoch: 1, offset_loss: 3570.45, state_loss: 0.2875, accuracy: 0.8987\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37e7ffd22b342ea906d82fbcfcc18a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 |  6460/ 6462 batches | ms/batch 98.43 | offset_loss 3534.94 | state_loss 0.2788 | accuracy 0.8991 | mse 1767.473\n",
      "Training: Epoch: 2, offset_loss: 3462.2360, state_loss: 0.2833\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521f50f747434ecf88b1ec5a67ed8f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Epoch: 2, offset_loss: 3301.85, state_loss: 0.2795, accuracy: 0.8991\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e833307de084805946a315af2ef8bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 |  6460/ 6462 batches | ms/batch 101.83 | offset_loss 3305.75 | state_loss 0.2761 | accuracy 0.8989 | mse 1652.87\n",
      "Training: Epoch: 3, offset_loss: 3323.0031, state_loss: 0.2777\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9218d6d8ed3440f9d8e5ef32c6d00bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Epoch: 3, offset_loss: 3226.47, state_loss: 0.2751, accuracy: 0.8993\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4658b8382ce4a6e8731bc3944cd1ea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   4 |  6460/ 6462 batches | ms/batch 99.35 | offset_loss 3170.81 | state_loss 0.2680 | accuracy 0.9028 | mse 1585.416\n",
      "Training: Epoch: 4, offset_loss: 3259.1606, state_loss: 0.2739\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2935390d70cb4a40967f977f177f6e16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Epoch: 4, offset_loss: 3174.92, state_loss: 0.2718, accuracy: 0.8997\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca2e9fd02867452b8486a945be34e31c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6462 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   5 |  6460/ 6462 batches | ms/batch 98.05 | offset_loss 3183.46 | state_loss 0.2714 | accuracy 0.8990 | mse 1591.733\n",
      "Training: Epoch: 5, offset_loss: 3218.7509, state_loss: 0.2707\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c4fe134e1046c3921c350746d9fda1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation: Epoch: 5, offset_loss: 3151.97, state_loss: 0.2690, accuracy: 0.8998\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_offset_loss, train_state_loss = train_model(model, train, optimizer, epoch)\n",
    "    print(f\"Training: Epoch: {epoch+1}, offset_loss: {train_offset_loss:5.4f}, state_loss: {train_state_loss:5.4f}\")\n",
    "    writer.add_scalar(\"Train/Loss/Epoch\", train_loss, epoch)\n",
    "    writer.add_scalar(\"Train/Offset_Loss/Epoch\", train_offset_loss, epoch)\n",
    "    writer.add_scalar(\"Train/State_Loss/Epoch\", train_state_loss, epoch)\n",
    "    \n",
    "    val_loss, val_offset_loss, val_state_loss, val_accuracy = evaluate_model(model, val)\n",
    "    print(f\"Validation: Epoch: {epoch+1}, offset_loss: {val_offset_loss:5.2f}, state_loss: {val_state_loss:5.4f}, accuracy: {val_accuracy:5.4f}\")\n",
    "    writer.add_scalar(\"Train/Loss/Epoch\", val_loss, epoch)\n",
    "    writer.add_scalar(\"Train/Offset_Loss/Epoch\", val_offset_loss, epoch)\n",
    "    writer.add_scalar(\"Train/State_Loss/Epoch\", val_state_loss, epoch)\n",
    "    \n",
    "    #scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13164b01790f4e998d52e5a0a4158121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: offset_loss: 3144.95, state_loss: 0.2695, accuracy: 0.8997\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_offset_loss, test_state_loss, test_accuracy = evaluate_model(model, test)\n",
    "print(f\"Test: offset_loss: {test_offset_loss:5.2f}, state_loss: {test_state_loss:5.4f}, accuracy: {test_accuracy:5.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./saved/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = customModel(nb=4, no=2, ns=2, embed_dim=32, state_hidden=128).to(\"cuda\")\n",
    "loaded_model.load('./saved/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef14dc3a4964177904bb42ad7c7c04c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/231 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: offset_loss: 3144.15, state_loss: 0.2694, accuracy: 0.8997\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_offset_loss, test_state_loss, test_accuracy = evaluate_model(loaded_model, test)\n",
    "print(f\"Test: offset_loss: {test_offset_loss:5.2f}, state_loss: {test_state_loss:5.4f}, accuracy: {test_accuracy:5.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20, 5])\n",
      "tensor([[[ 1.6000e+01, -5.0000e+00,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.9000e+01, -1.2000e+01,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 8.0000e+01, -5.6000e+01,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 2.2000e+01, -3.3000e+01,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.1000e+01, -2.9000e+01,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.7000e+01, -6.6000e+01,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 5.0000e+00, -3.8000e+01,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 2.0000e+00, -3.9400e+02,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 8.0000e+00, -3.7000e+01,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.3000e+01, -2.6000e+01,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.1000e+01, -3.2000e+01,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 5.7000e+01, -9.9000e+01,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 2.0000e+00,  1.0000e+01,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [-4.0000e+00,  3.3000e+01,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [-9.0000e+00,  4.0000e+01,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [-1.0000e+01,  8.4000e+01,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  1.2500e+02,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 1.2000e+01,  5.3000e+01,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 2.4000e+01,  8.0000e+01,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 5.0000e+01,  1.1400e+02,  1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 2.2015e+01,  5.2899e+01,  5.9373e+00,  4.6200e+00, -2.5969e+01],\n",
      "         [-1.5388e+02, -1.7300e+02,  5.7778e+00,  1.3754e-01, -1.7065e+01],\n",
      "         [ 2.9457e+01,  1.7077e+01,  2.8167e+00,  1.4754e+00, -1.0792e+01],\n",
      "         [-9.9505e+00, -6.4732e+01,  4.1840e+00,  4.5198e-01, -1.2707e+01],\n",
      "         [ 1.1341e+01,  1.5465e+01,  3.4614e+00,  2.0634e+00, -1.3639e+01],\n",
      "         [-4.8022e+00, -6.3826e+00,  5.0249e+00,  4.5083e-01, -1.5310e+01],\n",
      "         [ 1.2168e+01,  2.3922e+00,  1.6226e+00,  2.0910e+00, -8.4398e+00],\n",
      "         [ 2.7430e+00, -1.4811e+01,  4.2230e+00,  3.6254e-01, -1.2791e+01],\n",
      "         [ 1.0592e+01,  3.6148e+00,  9.8475e-01,  2.3099e+00, -6.8680e+00],\n",
      "         [ 2.6835e-01, -1.1404e+01,  4.1264e+00,  3.0967e-01, -1.2430e+01]]],\n",
      "       device='cuda:0')\n",
      "tensor([[  16.,   -5.,    1.,    0.,    0.],\n",
      "        [  19.,  -12.,    1.,    0.,    0.],\n",
      "        [  80.,  -56.,    1.,    0.,    0.],\n",
      "        [  22.,  -33.,    1.,    0.,    0.],\n",
      "        [  11.,  -29.,    1.,    0.,    0.],\n",
      "        [  17.,  -66.,    1.,    0.,    0.],\n",
      "        [   5.,  -38.,    1.,    0.,    0.],\n",
      "        [   2., -394.,    1.,    0.,    0.],\n",
      "        [   8.,  -37.,    1.,    0.,    0.],\n",
      "        [  13.,  -26.,    1.,    0.,    0.],\n",
      "        [  11.,  -32.,    1.,    0.,    0.],\n",
      "        [  57.,  -99.,    1.,    0.,    0.],\n",
      "        [   2.,   10.,    1.,    0.,    0.],\n",
      "        [  -4.,   33.,    1.,    0.,    0.],\n",
      "        [  -9.,   40.,    1.,    0.,    0.],\n",
      "        [ -10.,   84.,    1.,    0.,    0.],\n",
      "        [   0.,  125.,    1.,    0.,    0.],\n",
      "        [  12.,   53.,    1.,    0.,    0.],\n",
      "        [  24.,   80.,    1.,    0.,    0.],\n",
      "        [  50.,  114.,    1.,    0.,    0.],\n",
      "        [  27.,   75.,    1.,    0.,    0.],\n",
      "        [  12.,   25.,    1.,    0.,    0.],\n",
      "        [  69.,   51.,    1.,    0.,    0.],\n",
      "        [  27.,   35.,    1.,    0.,    0.],\n",
      "        [  30.,   58.,    1.,    0.,    0.],\n",
      "        [  17.,   22.,    1.,    0.,    0.],\n",
      "        [  14.,   15.,    1.,    0.,    0.],\n",
      "        [  31.,   20.,    0.,    1.,    0.],\n",
      "        [   0.,    0.,    0.,    0.,    1.],\n",
      "        [   0.,    0.,    0.,    0.,    1.]])\n"
     ]
    }
   ],
   "source": [
    "i = (train_dataset[0][0][:20]).unsqueeze(0)\n",
    "print(i.shape)\n",
    "print(model.generate(i.to(\"cuda\")))\n",
    "print(train_dataset[0][0][:30])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drawenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
